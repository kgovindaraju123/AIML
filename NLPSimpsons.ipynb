{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPSimpsons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeyw1ZBFWxOQ4hUhQDbNmH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgovindaraju123/AIML/blob/master/NLPSimpsons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwtkD4Cd-Q1I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "574f2f06-5948-4f0b-f02d-26a4a65e7280"
      },
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_lg==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.1.0/en_core_web_lg-2.1.0.tar.gz (826.9MB)\n",
            "\u001b[K     |████████████████████████████████| 826.9MB 1.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-2.1.0-cp36-none-any.whl size=828255078 sha256=70fc88d8b5f8146b17616a34756111dcdba1062258e54cb0c1c5a87d13f7d2d0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6jiq_xwv/wheels/b4/d7/70/426d313a459f82ed5e06cc36a50e2bb2f0ec5cb31d8e0bdf09\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYts5MZg-kAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "import pandas as pd\n",
        "from time import time\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "import logging\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s:%(message)s\",datefmt='%H:%M:%S',level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7GBvfDs_dSl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "d5d29129-439d-4843-be0e-734ac26c7344"
      },
      "source": [
        "df= pd.read_csv(\"simpsons_dataset.csv\")\n",
        "df.head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>spoken_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>No, actually, it was a little of both. Sometim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Where's Mr. Bergstrom?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  raw_character_text                                       spoken_words\n",
              "0        Miss Hoover  No, actually, it was a little of both. Sometim...\n",
              "1       Lisa Simpson                             Where's Mr. Bergstrom?\n",
              "2        Miss Hoover  I don't know. Although I'd sure like to talk t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsqo5JF__wgu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d336846d-bd98-420e-b14c-ccd224d0ed6d"
      },
      "source": [
        "#Verify Null\n",
        "df.isnull().sum()\n",
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(158314, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emdc2CeK_5b4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "6ebdd8c3-b8e8-4d23-e3e9-faee5be15351"
      },
      "source": [
        "#Remove Null\n",
        "df=df.dropna().reset_index(drop=True)\n",
        "df.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw_character_text    0\n",
              "spoken_words          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3ujq5OIAJjh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7f7e8eb-5ded-496b-a2ea-72c1b30100da"
      },
      "source": [
        "#Check again shape\n",
        "df.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(131853, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhnH-xajAYnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing part cleaning, Bigrams and most Frequent Words\n",
        "nlp=spacy.load('en_core_web_sm',disable=['ner','parser'])\n",
        "def cleaning(doc):\n",
        "  txt=[token.lemma_ for token in doc if not token.is_stop]\n",
        "  if len(txt)>2:\n",
        "    return ' '.join(txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cx2cavnA9k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove non alphabetic characters\n",
        "brief_cleaning=(re.sub(\"[^A-Za-z']+\", ' ',str(row)).lower() for row in df['spoken_words'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIYBLAnRClyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b30d39a-1a90-433e-b307-f32cefa84183"
      },
      "source": [
        "type(brief_cleaning)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bblBKHvTCpZx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "331bbb8a-fe36-4557-c08d-b2c4f60bd8af"
      },
      "source": [
        "#Define the pipeline\n",
        "t=time()\n",
        "txt=[cleaning(doc) for doc in nlp.pipe(brief_cleaning,batch_size=5000,n_threads=-1)]\n",
        "print('Time to clean up everything:{}mins'.format(round((time()-t)/60,2)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything:1.58mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9izhKeiDYvB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "efd1e881-f889-428c-b9b8-8eec380db192"
      },
      "source": [
        "type(txt)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vROXRzeDbTp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "156b1536-f22c-43e8-beef-420d5b3a742f"
      },
      "source": [
        "#DF to remove missing values and duplicates\n",
        "df_clean = pd.DataFrame({'Clean':txt})\n",
        "df_clean = df_clean.dropna().drop_duplicates()\n",
        "df_clean.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85962, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUgxMv05ElX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Bigrams - Gensim phases package automatically detect common phrases (bigrams=two word sentences) from a list of Sentences\n",
        "#Main reason to use bigram is to catch words like \"Mr_burns\" or \"bart_simpson\"\n",
        "from gensim.models.phrases import Phrases,Phraser"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfBeY1S3Fxk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Phrases takes a list of words as input\n",
        "sent=[row.split() for row in df_clean['Clean']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uePfWMLKJwpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#out put the sentences in DataFrame\n",
        "sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q42G2ZyGIdL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e26ed3c2-cf8e-4ae5-e614-347ed4ad4354"
      },
      "source": [
        "#creates the relvant phrases from list of sentences\n",
        "#progress per - write logs for every n sentences\n",
        "phrases=Phrases(sent,min_count=30,progress_per=10000)\n"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 04:38:15:collecting all words and their counts\n",
            "INFO - 04:38:15:PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 04:38:16:PROGRESS: at sentence #10000, processed 63561 words and 52712 word types\n",
            "INFO - 04:38:16:PROGRESS: at sentence #20000, processed 130943 words and 99633 word types\n",
            "INFO - 04:38:16:PROGRESS: at sentence #30000, processed 192972 words and 138210 word types\n",
            "INFO - 04:38:16:PROGRESS: at sentence #40000, processed 249843 words and 172231 word types\n",
            "INFO - 04:38:16:PROGRESS: at sentence #50000, processed 311269 words and 208040 word types\n",
            "INFO - 04:38:16:PROGRESS: at sentence #60000, processed 373589 words and 243067 word types\n",
            "INFO - 04:38:16:PROGRESS: at sentence #70000, processed 436445 words and 278006 word types\n",
            "INFO - 04:38:16:PROGRESS: at sentence #80000, processed 497905 words and 311099 word types\n",
            "INFO - 04:38:16:collected 329881 word types from a corpus of 537154 words (unigram + bigrams) and 85962 sentences\n",
            "INFO - 04:38:16:using 329881 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.phrases.Phrases"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJDc5n9TIy06",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d30253f-bdd9-4730-c6a6-3ac28827658b"
      },
      "source": [
        "type(phrases)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.phrases.Phrases"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv7TQHpUFxbK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d9a8f20f-781a-4146-d546-69dd3521cf4d"
      },
      "source": [
        "#Goal of phraser() is to cut down memeory consumption of Phrases()\n",
        "bigram = Phraser(phrases) #we cant see as it is a black box process"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 04:38:45:source_vocab length 329881\n",
            "INFO - 04:38:48:Phraser built with 126 phrasegrams\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voTudESUFxPB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "306f7a9d-f0f2-46fa-8237-4dc0a2b80baf"
      },
      "source": [
        "#transform the corpus based on the bigrams detected\n",
        "sentences=bigram[sent]\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyP9QWw3KAEU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "0ba18b05-b982-4210-f578-dc64716b6cde"
      },
      "source": [
        "#Example for Gensim Model Phrases\n",
        "documents = [\"Mr_Raju_Govind\"\"the mayor of new york was there\" \"machine learning can be useful sometimes\",\" new york mayor was present\"]\n",
        "sentence_stream=[doc.split(\" \")for doc in documents]\n",
        "print(sentence_stream)\n",
        "bigram=Phrases(sentence_stream,min_count=1,threshold=2)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 05:03:47:collecting all words and their counts\n",
            "INFO - 05:03:47:PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 05:03:47:collected 29 word types from a corpus of 18 words (unigram + bigrams) and 2 sentences\n",
            "INFO - 05:03:47:using 29 counts as vocab in Phrases<0 vocab, min_count=1, threshold=2, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[['Mr_Raju_Govindthe', 'mayor', 'of', 'new', 'york', 'was', 'theremachine', 'learning', 'can', 'be', 'useful', 'sometimes'], ['', 'new', 'york', 'mayor', 'was', 'present']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_luKLoaLxD3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "719e503d-b2e2-40b3-e01d-1251c930099e"
      },
      "source": [
        "#threshold - the minimum score for a bigram to be taken into account\n",
        "sents=[u'Mr_Raju_Govind',u'the',u'mayor',u'of',u'the',u'new',u'york',u'was',u'there']\n",
        "print(bigram[sents])"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Mr_Raju_Govind', 'the', 'mayor', 'of', 'the', 'new_york', 'was', 'there']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4qryKbWMYDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Most Frequent words sanity check of effectiveness of Lemmatization\n",
        "word_freq =defaultdict(int)\n",
        "for sent in sentences:\n",
        "  for i in sent:\n",
        "    word_freq[i]+=1\n",
        "    len(word_freq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Tazal4Nh3b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "0b1e36a5-9ef2-4045-e482-3a98c36e0130"
      },
      "source": [
        "word_freq"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {'_': 1,\n",
              "             'a': 2,\n",
              "             'e': 3,\n",
              "             'k': 1,\n",
              "             'm': 1,\n",
              "             'n': 2,\n",
              "             'o': 2,\n",
              "             'p': 1,\n",
              "             'r': 3,\n",
              "             's': 2,\n",
              "             't': 1,\n",
              "             'w': 2,\n",
              "             'y': 2})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTExy9Q8NhuR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "96fae9b4-ef27-4b2d-fae2-569ebf5f0664"
      },
      "source": [
        "#display 10 words in sort\n",
        "sorted(word_freq,key=word_freq.get,reverse=True)[:11]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e', 'r', 'n', 'w', 'y', 'o', 'a', 's', '_', 'k', 'm']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ0_NSPlPGFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "End of preprocessing step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIckH6MXPKen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training th model GENSIM word2vec implementation\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h5M2aZ7PXUK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5e24d96-d549-44d7-c0ff-5cb628492934"
      },
      "source": [
        "#to process the data speed, let us define cores\n",
        "cores=multiprocessing.cpu_count() # count the noof cores in a computer)\n",
        "cores"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaLL6BtTPtzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the Word2vec model\n",
        "w2v_model=Word2Vec(min_count=20,window=2,size=300,sample=6e-5,alpha=0.03,min_alpha=0.0007,negative=20,workers=cores-1)\n",
        "#min_count=ignoresall words with total frequency lower than value\n",
        "#window = max distance between the current and predicted word within a sentence\n",
        "#size =Dimensionality of feature vectors\n",
        "#alpha = initial learning rate\n",
        "#negative - negative sampleing will b eused how many noisy words are to be drawn\n",
        "#worker - use threads to train the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHnOvbu7RDML",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "f92d1da2-e8a1-4861-dd9a-8ac27a881c82"
      },
      "source": [
        "#Build the vocabulary table\n",
        "t=time()\n",
        "w2v_model.build_vocab(sentences,progress_per=10000)\n",
        "print('Time to build vocabulary:{}mins'.format(round((time()-t)/60,2)))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 05:32:28:collecting all words and their counts\n",
            "WARNING - 05:32:28:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n",
            "INFO - 05:32:28:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 05:32:28:collected 13 word types from a corpus of 23 raw words and 4 sentences\n",
            "INFO - 05:32:28:Loading a fresh vocabulary\n",
            "INFO - 05:32:28:effective_min_count=20 retains 0 unique words (0% of original 13, drops 13)\n",
            "INFO - 05:32:28:effective_min_count=20 leaves 0 word corpus (0% of original 23, drops 23)\n",
            "INFO - 05:32:28:deleting the raw counts dictionary of 13 items\n",
            "INFO - 05:32:28:sample=6e-05 downsamples 0 most-common words\n",
            "INFO - 05:32:28:downsampling leaves estimated 0 word corpus (0.0% of prior 0)\n",
            "INFO - 05:32:28:estimated required memory for 0 words and 300 dimensions: 0 bytes\n",
            "INFO - 05:32:28:resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocabulary:0.0mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FVnChnZStys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training model\n",
        "t=time()\n",
        "w2v_model.train(sentences,total_examples=w2v_model.corpus_count,epochs=30,report_delay=1)\n",
        "print('Time to train the model:{}mins'.format(round((time()-t)/60,2)))\n",
        "#Total examples - count the sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFX9HwVLTvEm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Use init_sims() make the model much more effiecient \n",
        "w2v_model.init_sims(relace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNP9pZpQT6K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Exploring the model\n",
        "#Ask our model to find the word most similar to some of most iconoc character\n",
        "w2v_model=wv.most_similar(positive=[\"homer\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsWzZ_UpUcxv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#bigram\n",
        "w2v_model=wv.most_similar(positive=[\"homer_simpson\"])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}