{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLPSimpsons.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRk80fneTgkbq6WK6bo9SL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgovindaraju123/AIML/blob/master/NLPSimpsons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwtkD4Cd-Q1I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYts5MZg-kAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re \n",
        "import pandas as pd\n",
        "from time import time\n",
        "from collections import defaultdict\n",
        "import spacy\n",
        "import logging\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s:%(message)s\",datefmt='%H:%M:%S',level=logging.INFO)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7GBvfDs_dSl",
        "colab_type": "code",
        "outputId": "81f61f2f-6489-40bb-958c-978c469816c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "df= pd.read_csv(\"simpsons_dataset.csv\")\n",
        "df.head(3)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>raw_character_text</th>\n",
              "      <th>spoken_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>No, actually, it was a little of both. Sometim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Lisa Simpson</td>\n",
              "      <td>Where's Mr. Bergstrom?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Miss Hoover</td>\n",
              "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  raw_character_text                                       spoken_words\n",
              "0        Miss Hoover  No, actually, it was a little of both. Sometim...\n",
              "1       Lisa Simpson                             Where's Mr. Bergstrom?\n",
              "2        Miss Hoover  I don't know. Although I'd sure like to talk t..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsqo5JF__wgu",
        "colab_type": "code",
        "outputId": "494bee2e-ab14-43fa-96f0-6025d2a12401",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Verify Null\n",
        "df.isnull().sum()\n",
        "df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(89058, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emdc2CeK_5b4",
        "colab_type": "code",
        "outputId": "49945f75-cedc-46ed-c720-4c05f01e8b04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "#Remove Null\n",
        "df=df.dropna().reset_index(drop=True)\n",
        "df.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw_character_text    0\n",
              "spoken_words          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3ujq5OIAJjh",
        "colab_type": "code",
        "outputId": "bcfd8bfa-e791-459a-8772-5fc020f5f626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Check again shape\n",
        "df.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(74574, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhnH-xajAYnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocessing part cleaning, Bigrams and most Frequent Words\n",
        "nlp=spacy.load('en_core_web_sm',disable=['ner','parser'])\n",
        "def cleaning(doc):\n",
        "  txt=[token.lemma_ for token in doc if not token.is_stop]\n",
        "  if len(txt)>2:\n",
        "    return ' '.join(txt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Cx2cavnA9k8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove non alphabetic characters\n",
        "brief_cleaning=(re.sub(\"[^A-Za-z']+\", ' ',str(row)).lower() for row in df['spoken_words'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIYBLAnRClyy",
        "colab_type": "code",
        "outputId": "5d5dbb6e-5d6f-445e-ee9b-32680226b34c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(brief_cleaning)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "generator"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bblBKHvTCpZx",
        "colab_type": "code",
        "outputId": "60525c2f-cda1-43ee-ee3c-bc7ea19d06c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Define the pipeline\n",
        "t=time()\n",
        "txt=[cleaning(doc) for doc in nlp.pipe(brief_cleaning,batch_size=5000,n_threads=-1)]\n",
        "print('Time to clean up everything:{}mins'.format(round((time()-t)/60,2)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything:0.89mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9izhKeiDYvB",
        "colab_type": "code",
        "outputId": "a3a21ec9-77b7-4fc2-b0d3-b6c9bb3f2835",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(txt)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vROXRzeDbTp",
        "colab_type": "code",
        "outputId": "9b9f852f-9652-4699-f29b-2b15ad463cf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#DF to remove missing values and duplicates\n",
        "df_clean = pd.DataFrame({'Clean':txt})\n",
        "df_clean = df_clean.dropna().drop_duplicates()\n",
        "df_clean.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48668, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUgxMv05ElX0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eac4a2dc-251e-4554-c899-fe07ae496cb1"
      },
      "source": [
        "#Bigrams - Gensim phases package automatically detect common phrases (bigrams=two word sentences) from a list of Sentences\n",
        "#Main reason to use bigram is to catch words like \"Mr_burns\" or \"bart_simpson\"\n",
        "from gensim.models.phrases import Phrases,Phraser"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 06:51:07:'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfBeY1S3Fxk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Phrases takes a list of words as input\n",
        "sent=[row.split() for row in df_clean['Clean']]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uePfWMLKJwpI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#out put the sentences in DataFrame\n",
        "sent"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q42G2ZyGIdL",
        "colab_type": "code",
        "outputId": "7b9d956e-e7ce-44fd-8c7c-02bbeb91dbc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#creates the relvant phrases from list of sentences\n",
        "#progress per - write logs for every n sentences\n",
        "phrases=Phrases(sent,min_count=30,progress_per=10000)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 06:51:24:collecting all words and their counts\n",
            "INFO - 06:51:24:PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 06:51:24:PROGRESS: at sentence #10000, processed 63561 words and 52712 word types\n",
            "INFO - 06:51:24:PROGRESS: at sentence #20000, processed 130943 words and 99633 word types\n",
            "INFO - 06:51:24:PROGRESS: at sentence #30000, processed 192972 words and 138210 word types\n",
            "INFO - 06:51:24:PROGRESS: at sentence #40000, processed 249843 words and 172231 word types\n",
            "INFO - 06:51:24:collected 203185 word types from a corpus of 302864 words (unigram + bigrams) and 48668 sentences\n",
            "INFO - 06:51:24:using 203185 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJDc5n9TIy06",
        "colab_type": "code",
        "outputId": "ac1f0744-c25a-4acc-bc52-1adf7691c911",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(phrases)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "gensim.models.phrases.Phrases"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv7TQHpUFxbK",
        "colab_type": "code",
        "outputId": "a2d94dec-8c2a-4e29-9ac9-a57880330786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Goal of phraser() is to cut down memeory consumption of Phrases()\n",
        "bigram = Phraser(phrases) #we cant see as it is a black box process"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 06:52:05:source_vocab length 203185\n",
            "INFO - 06:52:07:Phraser built with 67 phrasegrams\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "voTudESUFxPB",
        "colab_type": "code",
        "outputId": "e16d1a1a-0a3b-4da3-c872-4358257f47f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#transform the corpus based on the bigrams detected\n",
        "sentences=bigram[sent]\n",
        "sentences"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.interfaces.TransformedCorpus at 0x7fe047130cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uyP9QWw3KAEU",
        "colab_type": "code",
        "outputId": "3f97aee9-d302-4cef-b92c-440e6435ea85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "#Example for Gensim Model Phrases\n",
        "documents = [\"Mr_Raju_Govind\"\"the mayor of new york was there\" \"machine learning can be useful sometimes\",\" new york mayor was present\"]\n",
        "sentence_stream=[doc.split(\" \")for doc in documents]\n",
        "print(sentence_stream)\n",
        "bigram=Phrases(sentence_stream,min_count=1,threshold=2)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 06:52:25:collecting all words and their counts\n",
            "INFO - 06:52:25:PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 06:52:25:collected 29 word types from a corpus of 18 words (unigram + bigrams) and 2 sentences\n",
            "INFO - 06:52:25:using 29 counts as vocab in Phrases<0 vocab, min_count=1, threshold=2, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[['Mr_Raju_Govindthe', 'mayor', 'of', 'new', 'york', 'was', 'theremachine', 'learning', 'can', 'be', 'useful', 'sometimes'], ['', 'new', 'york', 'mayor', 'was', 'present']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_luKLoaLxD3",
        "colab_type": "code",
        "outputId": "68d61e4c-848a-478c-c3e5-5d5395e40600",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "#threshold - the minimum score for a bigram to be taken into account\n",
        "sents=[u'Mr_Raju_Govind',u'the',u'mayor',u'of',u'the',u'new',u'york',u'was',u'there']\n",
        "print(bigram[sents])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Mr_Raju_Govind', 'the', 'mayor', 'of', 'the', 'new_york', 'was', 'there']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4qryKbWMYDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Most Frequent words sanity check of effectiveness of Lemmatization\n",
        "word_freq =defaultdict(int)\n",
        "for sent in sentences:\n",
        "  for i in sent:\n",
        "    word_freq[i]+=1\n",
        "    len(word_freq)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3Tazal4Nh3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_freq"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTExy9Q8NhuR",
        "colab_type": "code",
        "outputId": "96fae9b4-ef27-4b2d-fae2-569ebf5f0664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#display 10 words in sort\n",
        "sorted(word_freq,key=word_freq.get,reverse=True)[:11]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['e', 'r', 'n', 'w', 'y', 'o', 'a', 's', '_', 'k', 'm']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ0_NSPlPGFN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "End of preprocessing step"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIckH6MXPKen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training th model GENSIM word2vec implementation\n",
        "import multiprocessing\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5h5M2aZ7PXUK",
        "colab_type": "code",
        "outputId": "6c16acb8-ba4f-4840-db60-21abc61f8c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#to process the data speed, let us define cores\n",
        "cores=multiprocessing.cpu_count() # count the noof cores in a computer)\n",
        "cores"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaLL6BtTPtzG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the Word2vec model\n",
        "w2v_model=Word2Vec(min_count=20,window=2,size=300,sample=6e-5,alpha=0.03,min_alpha=0.0007,negative=20,workers=cores-1)\n",
        "#min_count=ignoresall words with total frequency lower than value\n",
        "#window = max distance between the current and predicted word within a sentence\n",
        "#size =Dimensionality of feature vectors\n",
        "#alpha = initial learning rate\n",
        "#negative - negative sampleing will b eused how many noisy words are to be drawn\n",
        "#worker - use threads to train the model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHnOvbu7RDML",
        "colab_type": "code",
        "outputId": "b631b9c3-208f-4a3f-d3c2-b171b2292323",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "#Build the vocabulary table\n",
        "t=time()\n",
        "w2v_model.build_vocab(sentences,progress_per=10000)\n",
        "print('Time to build vocabulary:{}mins'.format(round((time()-t)/60,2)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 06:54:29:collecting all words and their counts\n",
            "INFO - 06:54:29:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 06:54:30:PROGRESS: at sentence #10000, processed 62066 words, keeping 9443 word types\n",
            "INFO - 06:54:30:PROGRESS: at sentence #20000, processed 128031 words, keeping 14327 word types\n",
            "INFO - 06:54:30:PROGRESS: at sentence #30000, processed 188835 words, keeping 17378 word types\n",
            "INFO - 06:54:30:PROGRESS: at sentence #40000, processed 244581 words, keeping 20069 word types\n",
            "INFO - 06:54:31:collected 22199 word types from a corpus of 296497 raw words and 48668 sentences\n",
            "INFO - 06:54:31:Loading a fresh vocabulary\n",
            "INFO - 06:54:31:effective_min_count=20 retains 2118 unique words (9% of original 22199, drops 20081)\n",
            "INFO - 06:54:31:effective_min_count=20 leaves 232809 word corpus (78% of original 296497, drops 63688)\n",
            "INFO - 06:54:31:deleting the raw counts dictionary of 22199 items\n",
            "INFO - 06:54:31:sample=6e-05 downsamples 1275 most-common words\n",
            "INFO - 06:54:31:downsampling leaves estimated 92775 word corpus (39.9% of prior 232809)\n",
            "INFO - 06:54:31:estimated required memory for 2118 words and 300 dimensions: 6142200 bytes\n",
            "INFO - 06:54:31:resetting layer weights\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocabulary:0.03mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FVnChnZStys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training model\n",
        "t=time()\n",
        "w2v_model.train(sentences,total_examples=w2v_model.corpus_count,epochs=30,report_delay=1)\n",
        "print('Time to train the model:{}mins'.format(round((time()-t)/60,2)))\n",
        "#Total examples - count the sentences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFX9HwVLTvEm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5a62a6c0-2ab1-4070-b480-3cde54fed9ae"
      },
      "source": [
        "#Use init_sims() make the model much more effiecient \n",
        "w2v_model.init_sims(replace=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 06:55:47:precomputing L2-norms of word weight vectors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNP9pZpQT6K4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "d8000cf7-a76c-47f6-f45c-f8001b7870ce"
      },
      "source": [
        "#Exploring the model\n",
        "#Ask our model to find the word most similar to some of most iconoc character\n",
        "w2v_model=w2v_model.most_similar(positive=[\"homer\"])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsWzZ_UpUcxv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "b5063569-16f1-4cbd-dc7d-935443c9b43c"
      },
      "source": [
        "#bigram\n",
        "w2v_model=w2v.most_similar(positive=[\"homer_simpson\"])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-c944eb4709db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"homer_simpson\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'w2v' is not defined"
          ]
        }
      ]
    }
  ]
}